{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7bb892c",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8001a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 3969\n",
      "Test size 997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergency Room Reports</td>\n",
       "      <td>REASON FOR THE VISIT:,  Very high PT/INR.,HIST...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>NAME OF PROCEDURE,1.  Selective coronary angio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         medical_specialty                                      transcription  \\\n",
       "0   Emergency Room Reports  REASON FOR THE VISIT:,  Very high PT/INR.,HIST...   \n",
       "1                  Surgery  PREOPERATIVE DIAGNOSIS:,  Acetabular fracture ...   \n",
       "2                  Surgery  NAME OF PROCEDURE,1.  Selective coronary angio...   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"new_train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"new_test.csv\", index_col=0)\n",
    "\n",
    "print(\"Train size\", len(train_df))\n",
    "print(\"Test size\", len(test_df))\n",
    "train_df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326d130",
   "metadata": {},
   "source": [
    "### Train Set Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c349df00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Surgery                          863\n",
       " Consult - History and Phy.       410\n",
       " Cardiovascular / Pulmonary       309\n",
       " Orthopedic                       289\n",
       " Radiology                        213\n",
       " General Medicine                 209\n",
       " Gastroenterology                 176\n",
       " Neurology                        170\n",
       " SOAP / Chart / Progress Notes    135\n",
       " Urology                          134\n",
       " Obstetrics / Gynecology          123\n",
       " Discharge Summary                 87\n",
       " ENT - Otolaryngology              82\n",
       " Neurosurgery                      71\n",
       " Hematology - Oncology             68\n",
       " Ophthalmology                     67\n",
       " Emergency Room Reports            63\n",
       " Nephrology                        63\n",
       " Pediatrics - Neonatal             55\n",
       " Pain Management                   54\n",
       " Psychiatry / Psychology           45\n",
       " Office Notes                      38\n",
       " Podiatry                          35\n",
       " Dermatology                       21\n",
       " Dentistry                         21\n",
       " Cosmetic / Plastic Surgery        19\n",
       " Letters                           19\n",
       " Endocrinology                     16\n",
       " Physical Medicine - Rehab         16\n",
       " Bariatrics                        15\n",
       " IME-QME-Work Comp etc.            12\n",
       " Chiropractic                      12\n",
       " Sleep Medicine                    12\n",
       " Diets and Nutritions               9\n",
       " Speech - Language                  8\n",
       " Autopsy                            7\n",
       " Hospice - Palliative Care          6\n",
       " Allergy / Immunology               6\n",
       " Rheumatology                       6\n",
       " Lab Medicine - Pathology           5\n",
       "Name: medical_specialty, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"medical_specialty\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8c8f3",
   "metadata": {},
   "source": [
    "### Sample Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4b315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('REASON FOR THE VISIT:,  Very high PT/INR.,HISTORY: , The patient is an '\n",
      " '81-year-old lady whom I met last month when she came in with pneumonia and '\n",
      " 'CHF.  She was noticed to be in atrial fibrillation, which is a chronic '\n",
      " 'problem for her.  She did not want to have Coumadin started because she said '\n",
      " 'that she has had it before and the INR has had been very difficult to '\n",
      " 'regulate to the point that it was dangerous, but I convinced her to restart '\n",
      " 'the Coumadin again.  I gave her the Coumadin as an outpatient and then the '\n",
      " 'INR was found to be 12.  So, I told her to come to the emergency room to get '\n",
      " 'vitamin K to reverse the anticoagulation.,PAST MEDICAL HISTORY:,1.  '\n",
      " 'Congestive heart failure.,2.  Renal insufficiency.,3.  Coronary artery '\n",
      " 'disease.,4.  Atrial fibrillation.,5.  COPD.,6.  Recent pneumonia.,7.  '\n",
      " 'Bladder cancer.,8.  History of ruptured colon.,9.  Myocardial '\n",
      " 'infarction.,10.  Hernia repair.,11.  Colon resection.,12.  Carpal tunnel '\n",
      " 'repair.,13.  Knee surgery.,MEDICATIONS:,1.  Coumadin.,2.  Simvastatin.,3.  '\n",
      " 'Nitrofurantoin.,4.  Celebrex.,5.  Digoxin.,6.  Levothyroxine.,7.  '\n",
      " 'Vicodin.,8.  Triamterene and hydrochlorothiazide.,9.  Carvedilol.,SOCIAL '\n",
      " 'HISTORY:  ,She does not smoke and she does not drink.,PHYSICAL '\n",
      " 'EXAMINATION:,GENERAL:  Lady in no distress.,VITAL SIGNS:  Blood pressure '\n",
      " '100/46, pulse of 75, respirations 12, and temperature 98.2.,HEENT:  Head is '\n",
      " 'normal.,NECK:  Supple.,LUNGS:  Clear to auscultation and percussion.,HEART:  '\n",
      " 'No S3, no S4, and no murmurs.,ABDOMEN:  Soft.,EXTREMITIES:  Lower '\n",
      " 'extremities, no edema.,ASSESSMENT:,1.  Atrial fibrillation.,2.  '\n",
      " 'Coagulopathy, induced by Coumadin.,PLAN: , Her INR at the office was 12.  I '\n",
      " 'will repeat it, and if it is still elevated, I will give vitamin K 10 mg in '\n",
      " '100 mL of D5W and then send her home and repeat the PT/INR next week.  I '\n",
      " 'believe at this time that it is too risky to use Coumadin in her case '\n",
      " 'because of her age and comorbidities, the multiple medications that she '\n",
      " 'takes and it is very difficult to keep an adequate level of anticoagulation '\n",
      " 'that is safe for her.  She is prone to a fall and this would be a big '\n",
      " 'problem.  We will use one aspirin a day instead of the anticoagulation.  She '\n",
      " 'is aware of the risk of stroke, but she is very scared of the '\n",
      " 'anticoagulation with Coumadin and does not want to use the Coumadin at this '\n",
      " 'time and I understand.  We will see her as an outpatient.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(train_df.transcription[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1b6f4d",
   "metadata": {},
   "source": [
    "### Sample Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68977658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "from torch import nn\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e142223",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = train_df[\"medical_specialty\"].unique()\n",
    "\n",
    "# idx_2_class = {i: s for i, s in enumerate(unique_classes)}\n",
    "# class_2_idx = {s: i for i, s in enumerate(unique_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac5d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\"labels\"] = train_df[\"medical_specialty\"].apply(lambda s: class_2_idx[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "233a4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train_df, train_test_df = \\\n",
    "    train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449f16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = {\n",
    "    'train': Dataset.from_pandas(train_train_df),\n",
    "    'val': Dataset.from_pandas(train_test_df),\n",
    "    \"test\": Dataset.from_pandas(test_df)\n",
    "}\n",
    "\n",
    "ds = DatasetDict(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a995f402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6ee68ccb5844bf8a7ef1736274e442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d72b7eadcf485aa898b4fcb9c89d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00307d96c1f74a10a7447c60d27b3e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_text(texts):\n",
    "    return tokenizer(texts[\"transcription\"], truncation=True, padding=True, max_length=256)\n",
    "\n",
    "ds[\"train\"] = ds[\"train\"].map(tokenize_text, batched=True)\n",
    "ds[\"val\"] = ds[\"val\"].map(tokenize_text, batched=True)\n",
    "ds[\"test\"] = ds[\"test\"].map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa6c4319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(unique_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ca876",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f26fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414f5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "logging_steps = len(train_train_df) // batch_size\n",
    "output_dir = \"hf_trainer\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "     num_train_epochs=5,\n",
    "     learning_rate=2e-5,\n",
    "     per_device_train_batch_size=batch_size,\n",
    "     per_device_eval_batch_size=batch_size,\n",
    "     weight_decay=0.01,\n",
    "     evaluation_strategy=\"epoch\",\n",
    "     logging_steps=logging_steps,\n",
    "     push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "994876be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds['val'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8cfca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, medical_specialty, transcription. If __index_level_0__, medical_specialty, transcription are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\alvin\\miniconda3\\envs\\hf\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2778\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 435\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='435' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [435/435 06:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.045300</td>\n",
       "      <td>2.807685</td>\n",
       "      <td>0.024263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.583900</td>\n",
       "      <td>2.633775</td>\n",
       "      <td>0.036012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.438700</td>\n",
       "      <td>2.529113</td>\n",
       "      <td>0.050857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.344900</td>\n",
       "      <td>2.458471</td>\n",
       "      <td>0.053919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.267800</td>\n",
       "      <td>2.432428</td>\n",
       "      <td>0.054719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, medical_specialty, transcription. If __index_level_0__, medical_specialty, transcription are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1191\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, medical_specialty, transcription. If __index_level_0__, medical_specialty, transcription are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1191\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, medical_specialty, transcription. If __index_level_0__, medical_specialty, transcription are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1191\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, medical_specialty, transcription. If __index_level_0__, medical_specialty, transcription are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1191\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, medical_specialty, transcription. If __index_level_0__, medical_specialty, transcription are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1191\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=435, training_loss=2.5318976632479964, metrics={'train_runtime': 403.981, 'train_samples_per_second': 34.383, 'train_steps_per_second': 1.077, 'total_flos': 920609536204800.0, 'train_loss': 2.5318976632479964, 'epoch': 5.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6603a",
   "metadata": {},
   "source": [
    "### Making Inference on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3bc4a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['transcription', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 997\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0d1f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: __index_level_0__, transcription. If __index_level_0__, transcription are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 997\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y = trainer.predict(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0411c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(pred_y.predictions.argmax(axis=1))\n",
    "a.name = \"Expected\"\n",
    "a.to_csv(\"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
